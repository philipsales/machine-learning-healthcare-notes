{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI for Medicine Course 3 Week 1 lecture notebook - Model Training/Tuning Basics with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this exercise! You're going to be exploring the `sklearn` library, including an overview of its underlying data types and methods for tweaking a model's hyperparameters. You'll be using the same data from the previous lecture notebook. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "First import all the packages that you need for this assignment. \n",
    "\n",
    "\n",
    "- `pandas` is what you'll use to manipulate your data\n",
    "- `numpy`  is a library for mathematical and scientific operations\n",
    "- `sklearn` has many efficient tools for machine learning and statistical modeling\n",
    "- `itertools` helps with hyperparameter (grid) searching\n",
    "\n",
    "### Import Packages\n",
    "\n",
    "Run the next cell to import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Set the random seed for consistent output\n",
    "np.random.seed(18)\n",
    "\n",
    "# Read in the data\n",
    "data = pd.read_csv(\"dummy_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for training: 37\n",
      "Number of observations for testing: 13\n"
     ]
    }
   ],
   "source": [
    "# Import module to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the label\n",
    "y = data.outcome\n",
    "\n",
    "# Get the features\n",
    "X = data.drop('outcome', axis=1) \n",
    "\n",
    "# Get training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "print(f\"Number of observations for training: {y_train.size}\")\n",
    "print(f\"Number of observations for testing: {y_test.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>obstruct</th>\n",
       "      <th>TRTMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  age  obstruct  TRTMT\n",
       "29    0   56         1  False\n",
       "67    1   49         0   True\n",
       "59    0   65         0  False\n",
       "68    1   60         0  False\n",
       "2     1   68         0  False\n",
       "42    0   39         1  False\n",
       "27    0   70         0  False\n",
       "12    1   52         0   True\n",
       "37    1   79         0  False\n",
       "63    0   53         0  False\n",
       "41    1   75         0   True\n",
       "10    0   68         0   True\n",
       "55    1   61         0   True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fit and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a logistic regression to the training data. `Sklearn` allows you to provide arguments that override the defaults. \n",
    "\n",
    "The default solver is `lbfgs`.  \n",
    "- Lbfgs stands for ['Limited Memory BFGS'](https://en.wikipedia.org/wiki/Limited-memory_BFGS), and is an efficient and popular method for fitting models.\n",
    "- The solver is set explicitly here for learning purposes; if you do not set the solver parameter explicitly, the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) function will use its default solver, which is lbfgs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it fits the training data, `sklearn` also prints out the model's hyperparameters.  \n",
    "- Here, these are the default hyperparameters for `sklearn's` logistic regression classifier.\n",
    "- Another way to check these parameters is the `get_params()` method of the classifier.\n",
    "\n",
    "You should spend some time checking out the [documentation](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) to get a deeper understanding of what's going on. One important thing to note is that each classifier has different hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "To predict with the classifier, use the `predict()` method. \n",
    "- This returns a `numpy` array containing the predicted class for each observation in the test set, as you can see by running the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions is of type: <class 'numpy.ndarray'>\n",
      "predictions has shape: (13,)\n",
      "predicted class for 10th element in test set: 0\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict labels from the features of the test set\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "# View the prediction type, shape, and print out a sample prediction\n",
    "print(f\"predictions is of type: {type(predictions)}\")\n",
    "print(f\"predictions has shape: {predictions.shape}\")\n",
    "print(f\"predicted class for 10th element in test set: {predictions[9]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction probability\n",
    "\n",
    "When a model predicts that a label is 1 rather than 0, it may help you to know if the model was predicting 1 with a 51% probability or 90% probability; in other words, how confident is that prediction?\n",
    "\n",
    "You can get the model's probability of predicting each of the class. \n",
    "- To do this, use the `predict_proba()` method. \n",
    "- The resulting array will have a shape that matches the number of classes for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_probs is of type: <class 'numpy.ndarray'>\n",
      "prediction_probs has shape: (13, 2)\n",
      "probabilities for first element in test set: [0.56628451 0.43371549]\n"
     ]
    }
   ],
   "source": [
    "prediction_probs = lr.predict_proba(X_test)\n",
    "print(f\"prediction_probs is of type: {type(prediction_probs)}\")\n",
    "print(f\"prediction_probs has shape: {prediction_probs.shape}\")\n",
    "print(f\"probabilities for first element in test set: {prediction_probs[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56628451, 0.43371549],\n",
       "       [0.75636547, 0.24363453],\n",
       "       [0.56566588, 0.43433412],\n",
       "       [0.64698806, 0.35301194],\n",
       "       [0.58104218, 0.41895782],\n",
       "       [0.70247262, 0.29752738],\n",
       "       [0.52247396, 0.47752604],\n",
       "       [0.73658921, 0.26341079],\n",
       "       [0.48593882, 0.51406118],\n",
       "       [0.66426272, 0.33573728],\n",
       "       [0.55646897, 0.44353103],\n",
       "       [0.57526527, 0.42473473],\n",
       "       [0.671438  , 0.328562  ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56628451, 0.75636547, 0.56566588, 0.64698806, 0.58104218,\n",
       "       0.70247262, 0.52247396, 0.73658921, 0.48593882, 0.66426272,\n",
       "       0.55646897, 0.57526527, 0.671438  ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>obstruct</th>\n",
       "      <th>TRTMT</th>\n",
       "      <th>preditions</th>\n",
       "      <th>prob_alive_5years</th>\n",
       "      <th>prob_died_5years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566285</td>\n",
       "      <td>0.433715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756365</td>\n",
       "      <td>0.243635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565666</td>\n",
       "      <td>0.434334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646988</td>\n",
       "      <td>0.353012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581042</td>\n",
       "      <td>0.418958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702473</td>\n",
       "      <td>0.297527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522474</td>\n",
       "      <td>0.477526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736589</td>\n",
       "      <td>0.263411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485939</td>\n",
       "      <td>0.514061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664263</td>\n",
       "      <td>0.335737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.556469</td>\n",
       "      <td>0.443531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575265</td>\n",
       "      <td>0.424735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671438</td>\n",
       "      <td>0.328562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  age  obstruct  TRTMT  preditions  prob_alive_5years  prob_died_5years\n",
       "29    0   56         1  False           0           0.566285          0.433715\n",
       "67    1   49         0   True           0           0.756365          0.243635\n",
       "59    0   65         0  False           0           0.565666          0.434334\n",
       "68    1   60         0  False           0           0.646988          0.353012\n",
       "2     1   68         0  False           0           0.581042          0.418958\n",
       "42    0   39         1  False           0           0.702473          0.297527\n",
       "27    0   70         0  False           0           0.522474          0.477526\n",
       "12    1   52         0   True           0           0.736589          0.263411\n",
       "37    1   79         0  False           1           0.485939          0.514061\n",
       "63    0   53         0  False           0           0.664263          0.335737\n",
       "41    1   75         0   True           0           0.556469          0.443531\n",
       "10    0   68         0   True           0           0.575265          0.424735\n",
       "55    1   61         0   True           0           0.671438          0.328562"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = X_test.copy()\n",
    "result_df['preditions'] = predictions\n",
    "result_df['prob_alive_5years'] = prediction_probs[:,0]\n",
    "result_df['prob_died_5years'] = prediction_probs[:,1]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 patients in the test set.  Each patient's label could be either 0 or 1, so the prediction probability has 13 rows and 2 columns.  To know which column refers to lable 0 and which refers to label 1, you can check the `.classes_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the order of the `classes_` array is 0, then 1, column 0 of the prediction probabilities has label 0, and column 1 has label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print these for the first 5 elements of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element number: 0\n",
      "Predicted class: 0\n",
      "Probability of predicting class 0: 0.5662845082707992\n",
      "Probability of predicting class 1: 0.43371549172920076\n",
      "\n",
      "Element number: 1\n",
      "Predicted class: 0\n",
      "Probability of predicting class 0: 0.7563654690608839\n",
      "Probability of predicting class 1: 0.24363453093911608\n",
      "\n",
      "Element number: 2\n",
      "Predicted class: 0\n",
      "Probability of predicting class 0: 0.5656658810530872\n",
      "Probability of predicting class 1: 0.4343341189469128\n",
      "\n",
      "Element number: 3\n",
      "Predicted class: 0\n",
      "Probability of predicting class 0: 0.6469880579701954\n",
      "Probability of predicting class 1: 0.3530119420298045\n",
      "\n",
      "Element number: 4\n",
      "Predicted class: 0\n",
      "Probability of predicting class 0: 0.5810421781156221\n",
      "Probability of predicting class 1: 0.41895782188437797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Element number: {i}\")\n",
    "    print(f\"Predicted class: {predictions[i]}\")\n",
    "    print(f\"Probability of predicting class 0: {prediction_probs[i][0]}\")\n",
    "    print(f\"Probability of predicting class 1: {prediction_probs[i][1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the predicted class matches the class with a higher probability of being predicted. Since you're dealing with `numpy` arrays, you can simply slice them and get specific information, such as the probability of predicting class 1 for all elements in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43371549, 0.24363453, 0.43433412, 0.35301194, 0.41895782,\n",
       "       0.29752738, 0.47752604, 0.26341079, 0.51406118, 0.33573728,\n",
       "       0.44353103, 0.42473473, 0.328562  ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve prediction probabilities for label 1, for all patients\n",
    "prediction_probs[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, the predictive power of a classifier can be increased if a good set of hyperparameters is defined. This is known as model tuning. \n",
    "\n",
    "For this process, you'll need a classifier, an appropriate evaluation metric, and a set of parameters to test. Since this is a dummy example, you'll use the default metric for the logistic regression classifier: the **mean accuracy**.\n",
    "\n",
    "### Mean Accuracy\n",
    "Mean Accuracy is the number of correct predictions divided by total predictions. This can be computed with the `score()` method. \n",
    "\n",
    "Let's begin by checking the performance of your out-of-the-box logit classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to tweak this model's default parameters. You can pass a dictionary containing the values you specify to the classifier when you instantiate it. Notice that these must be passed as keyword arguments, or `kwargs`, which are created by using the ** prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweaked hyperparameters: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': False, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Mean Accuracy: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "# Choose hyperparameters and place them as key-value pairs in a dictionary\n",
    "params = {\n",
    "    'solver': 'liblinear',\n",
    "    'fit_intercept': False,\n",
    "    'penalty': 'l1',\n",
    "    'max_iter': 500\n",
    "}\n",
    "\n",
    "# Pass in the dictionary as keyword arguments to the model\n",
    "lr_tweaked = LogisticRegression(**params)\n",
    "\n",
    "# Train the model\n",
    "lr_tweaked.fit(X_train, y_train)\n",
    "\n",
    "# View hyper-parameters\n",
    "print(f\"Tweaked hyperparameters: {lr_tweaked.get_params()}\\n\")\n",
    "\n",
    "# Evaluate the model with the mean accuracy\n",
    "print(f\"Mean Accuracy: {lr_tweaked.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the tweaked parameters is worse than the original! However, there might still be some combination of parameters that increase the predictive power of your logit classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different hyperparameters\n",
    "Testing this can be daunting considering all the possible parameter combinations. Let's try something \n",
    "\n",
    "To get started, you'll apply `itertools.product()` to create all the combinations of parameters. \n",
    "- Notice that the iterable (in this case a list of the lists of parameters) must be passed as *args to the `product()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['liblinear'], [True, False], ['l1', 'l2'], [None, 'balanced']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hyperparameters and place in a dictionary\n",
    "hyperparams = {\n",
    "    'solver': [\"liblinear\"],\n",
    "    'fit_intercept': [True, False],\n",
    "    'penalty': [\"l1\", \"l2\"],\n",
    "    'class_weight': [None, \"balanced\"]\n",
    "}\n",
    "# Get the values of hyperparams and convert them to a list of lists\n",
    "hp_values = list(hyperparams.values())\n",
    "hp_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('liblinear', True, 'l1', None)\n",
      "('liblinear', True, 'l1', 'balanced')\n",
      "('liblinear', True, 'l2', None)\n",
      "('liblinear', True, 'l2', 'balanced')\n",
      "('liblinear', False, 'l1', None)\n",
      "('liblinear', False, 'l1', 'balanced')\n",
      "('liblinear', False, 'l2', None)\n",
      "('liblinear', False, 'l2', 'balanced')\n"
     ]
    }
   ],
   "source": [
    "# Get every combination of the hyperparameters\n",
    "for hp in itertools.product(*hp_values):\n",
    "    print(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used: ('liblinear', True, 'l1', None)\n",
      "Mean accuracy of the model: 0.5384615384615384\n",
      "\n",
      "Parameters used: ('liblinear', True, 'l1', 'balanced')\n",
      "Mean accuracy of the model: 0.46153846153846156\n",
      "\n",
      "Parameters used: ('liblinear', True, 'l2', None)\n",
      "Mean accuracy of the model: 0.5384615384615384\n",
      "\n",
      "Parameters used: ('liblinear', True, 'l2', 'balanced')\n",
      "Mean accuracy of the model: 0.6153846153846154\n",
      "\n",
      "Parameters used: ('liblinear', False, 'l1', None)\n",
      "Mean accuracy of the model: 0.5384615384615384\n",
      "\n",
      "Parameters used: ('liblinear', False, 'l1', 'balanced')\n",
      "Mean accuracy of the model: 0.46153846153846156\n",
      "\n",
      "Parameters used: ('liblinear', False, 'l2', None)\n",
      "Mean accuracy of the model: 0.5384615384615384\n",
      "\n",
      "Parameters used: ('liblinear', False, 'l2', 'balanced')\n",
      "Mean accuracy of the model: 0.6923076923076923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the combinations of hyperparams\n",
    "for hp in itertools.product(*hp_values):\n",
    "\n",
    "    # Create the model with the hyperparams\n",
    "    estimator = LogisticRegression(solver=hp[0],\n",
    "                                   fit_intercept=hp[1],\n",
    "                                   penalty=hp[2],\n",
    "                                   class_weight=hp[3])\n",
    "    # Fit the model\n",
    "    estimator.fit(X_train, y_train)\n",
    "    print(f\"Parameters used: {hp}\")\n",
    "    print(f\"Mean accuracy of the model: {estimator.score(X_test, y_test)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the graded assignment, you will take a more generalizable approach that doesn't require you to explicitly specify each hyperparameter.\n",
    "\n",
    "That is, instead of:\n",
    "\n",
    "```CPP\n",
    "LogisticRegression(solver=hp[0],fit_intercept=hp[1],...\n",
    "```\n",
    "\n",
    "You'll be able to write:\n",
    "```CPP\n",
    "LogisticRegression(**params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like none of these models beats the original! This won't always be the case, so next time the opportunity arises, you'll be able to check this for yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "This is essentially grid search.  You'll be implementing customized grid search in the graded assignment.  \n",
    "- Note that even though sci-kit learn provides a grid search function, it uses K-fold cross validation, which you won't want to do in the assignment, which is why you will implement grid search yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations on completing this lecture notebook! \n",
    "\n",
    "By now, you should feel more comfortable with the `sklearn` library and how it works. You also created a grid search from scratch by leveraging the `itertools` library. Nice work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
